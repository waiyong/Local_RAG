# config.py

# model path
MODEL_PATH = "./quantized_model/mistral-7b-instruct-v0.2.Q4_K_M.gguf"
# Embedding Model Path
EMBEDDING_MODEL_NAME = "BAAI/bge-small-en-v1.5"
EMBEDDING_MODEL_PATH = "./embedding_model"

# Document Directory
DOCUMENT_PATH = "./Document"
DOCUMENT_PATH_PERSONAL = "./Document_Personal"

# Retrieval settings
TOP_K = 3  # Number of retrieved documents

# Query Engine Settings
MAX_TOKENS_GENERATE = 512  # Maximum number of tokens generated by the model

# Memory Legnth
MEMORY_LENGTH = 1024  # Number of previous messages to consider

# Chainlit settings
HOST = "0.0.0.0"
PORT = 8000
